{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "---------- Update from node agent ---------\n",
                        "{'messages': [AIMessage(content='Guten Tag! Ich bin der KI-Assistent für Neurapolis, das Ratsdokumentenmanagementsystem der Stadt Freiburg. Wie kann ich Ihnen heute helfen? Haben Sie Fragen zu städtischen Angelegenheiten, Verordnungen oder aktuellen Projekten in Freiburg?', additional_kwargs={'usage': {'prompt_tokens': 1041, 'completion_tokens': 85, 'total_tokens': 1126}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 1041, 'completion_tokens': 85, 'total_tokens': 1126}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-236a915d-bce5-49c6-98d9-deba1212dbdf-0', usage_metadata={'input_tokens': 1041, 'output_tokens': 85, 'total_tokens': 1126})]}\n"
                    ]
                }
            ],
            "source": [
                "import uuid\n",
                "import asyncio\n",
                "import nest_asyncio\n",
                "# Apply nest_asyncio to allow running asyncio in Jupyter\n",
                "nest_asyncio.apply()\n",
                "\n",
                "thread_id = str(uuid.uuid4())\n",
                "\n",
                "config = {\n",
                "    \"configurable\": {\n",
                "        \"thread_id\": thread_id,\n",
                "    }\n",
                "}\n",
                "\n",
                "from neurapolis_cognitive_architecture.agent import graph\n",
                "from langchain_core.messages import HumanMessage\n",
                "\n",
                "async def process_user_input(user_input):\n",
                "    \n",
                "    inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
                "    async for chunk in graph.astream(inputs, config=config, stream_mode=\"updates\"):\n",
                "        node_name = list(chunk.keys())[0]\n",
                "        print(f\"---------- Update from node {node_name} ---------\")\n",
                "        print(chunk[node_name])\n",
                "async def main():\n",
                "    while True:\n",
                "        user_input = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
                "        if user_input.lower() == \"exit\":\n",
                "            break\n",
                "        await process_user_input(user_input)\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    asyncio.run(main())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}